#!/usr/bin/env python

# autobib - Automatically generates a bibtex file from pdf's.
# Copyright (C) 2010  Joacim Alvergren <joacim.alvergren at gmail.com>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
# 02110-1301,  USA.

import urllib2
import re
import hashlib
import random
import sys
import os
import subprocess
import optparse
import logging

from BeautifulSoup import BeautifulSoup

google_id = hashlib.md5(str(random.random())).hexdigest()[:16]
GOOGLE_SCHOLAR_URL = "http://scholar.google.com"
HEADERS = {'User-Agent' : 'Mozilla/5.0',
           'Cookie' : 'GSP=ID=%s:CF=4' % google_id }
BIB_FILE = 'bibtex.bib'

def create_bibtex(args):
    file = open(BIB_FILE, 'w')
    file.write('@comment{This file has been generated by autobib}\n\n')
    for filename in os.listdir(args):
        if filename.lower()[-3:] == "pdf":
            bib = get_pdf_bibtex(filename)
            if bib != None:
                file.write(bib + '\n')
            else:
                file.write('ERROR: Could not find bibtex for:\n%s on %s\n\n'  % (filename, GOOGLE_SCHOLAR_URL))
    file.close()

def get_pdf_bibtex(pdf):
    txt = pdf_to_txt(pdf)
    txt = re.sub("\W", " ", txt)
    words = txt.strip().split()[:20]
    search_str = " ".join(words)
    bib = search(search_str)
    return bib

def search(search_str):
    logging.debug("Search: %s" % search_str)
    search_str = '/scholar?q=' + urllib2.quote(search_str)
    url = GOOGLE_SCHOLAR_URL + search_str
    request = urllib2.Request(url, headers=HEADERS)
    response = urllib2.urlopen(request)
    html = response.read()
    html.decode('ascii', 'ignore') 
    soup = BeautifulSoup(html)
    link = soup.findAll('a', href=re.compile("^/scholar.bib"))
    if len(link) != 0:
        url = link[0]["href"]
        url = GOOGLE_SCHOLAR_URL+url
        request = urllib2.Request(url, headers=HEADERS)
        response = urllib2.urlopen(request)
        bib = response.read()
        return bib

def pdf_to_txt(pdf):
    stdout = subprocess.Popen(["pdftotext", "-q", pdf, "-"], stdout=subprocess.PIPE).communicate()[0]
    return stdout

if __name__ == "__main__":
    usage = "Usage: %prog [options] {path to pdf's}"
    parser = optparse.OptionParser(usage)
    parser.add_option("-d", "--debug", action="store_true", dest="debug",
                      default="False", help="show debugging output")
    
    (options, args) = parser.parse_args()
    if options.debug == True:
        logging.basicConfig(level=logging.DEBUG)
    if len(args) != 1:
        args = '.'
    else: args = args[0]
    if os.path.exists(args):
        create_bibtex(args)
